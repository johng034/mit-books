{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Page Links\n",
    "Since there are multiple pages, we will get the links for each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ({'User-Agent':\n",
    "           'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko)Chrome/44.0.2403.157 Safari/537.36',\n",
    "                           'Accept-Language': 'en-US, en;q=0.5'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "The URL has changed, so I have rewritten the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://mitpress.mit.edu/search-result-list/?keyword=essential+knowledge&series=mit-press-essential-knowledge-series&page_number='\n",
    "get_url = lambda x: url + f'{x}'\n",
    "\n",
    "\n",
    "num = 12\n",
    "page = requests.get(get_url(num), headers=headers)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "while soup.findAll(class_ = 'supapress-page') == []:\n",
    "    num -= 1\n",
    "\n",
    "    page = requests.get(get_url(num), headers=headers)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of URLs\n",
    "pages = []\n",
    "\n",
    "for page in range(1, num+1):\n",
    "    pages.append(get_url(page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://mitpress.mit.edu/search-result-list/?keyword=essential+knowledge&series=mit-press-essential-knowledge-series&page_number=1\n",
      "https://mitpress.mit.edu/search-result-list/?keyword=essential+knowledge&series=mit-press-essential-knowledge-series&page_number=2\n",
      "https://mitpress.mit.edu/search-result-list/?keyword=essential+knowledge&series=mit-press-essential-knowledge-series&page_number=3\n",
      "https://mitpress.mit.edu/search-result-list/?keyword=essential+knowledge&series=mit-press-essential-knowledge-series&page_number=4\n",
      "https://mitpress.mit.edu/search-result-list/?keyword=essential+knowledge&series=mit-press-essential-knowledge-series&page_number=5\n",
      "https://mitpress.mit.edu/search-result-list/?keyword=essential+knowledge&series=mit-press-essential-knowledge-series&page_number=6\n",
      "https://mitpress.mit.edu/search-result-list/?keyword=essential+knowledge&series=mit-press-essential-knowledge-series&page_number=7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(page) for page in pages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information to be Collected\n",
    "We are going to collect the following data from each book:\n",
    "- Title\n",
    "- Author\n",
    "- Number of pages\n",
    "- Link to book\n",
    "- Link to author's webpage(s)\n",
    "- Publish Date\n",
    "- Price\n",
    "- Link to purchase the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to add data\n",
    "titles  = []\n",
    "links   = []\n",
    "\n",
    "for page in pages:\n",
    "    # Create soup\n",
    "    raw_page = requests.get(page)\n",
    "    soup = BeautifulSoup(raw_page.content, 'html.parser')\n",
    "\n",
    "    # Get relevant html\n",
    "    results = soup.findAll(class_ = \"information-wrapper\")\n",
    "    \n",
    "    for data in results:\n",
    "        \n",
    "        # Get the title\n",
    "        title = data.find(class_ = 'sp__the-title')\n",
    "        full_title = title.string\n",
    "        \n",
    "        if full_title is None:\n",
    "            new_html = data.find(class_ = 'sp__the-title').a\n",
    "            title_list = [string for string in new_html.stripped_strings]\n",
    "            full_title = ' '.join(title_list)\n",
    "            \n",
    "        titles.append(full_title)\n",
    "        \n",
    "        # Get the URL\n",
    "        url_ending = data.find(class_ = 'sp__the-title').a.get('href')\n",
    "        links.append('https://mitpress.mit.edu' + url_ending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = []\n",
    "authors_webpages = []\n",
    "publish_dates = []\n",
    "book_length = []\n",
    "prices = []\n",
    "purchase_links = []\n",
    "\n",
    "for link in links:\n",
    "    # Create soup\n",
    "    raw_page = requests.get(link)\n",
    "    soup = BeautifulSoup(raw_page.content, 'html.parser')\n",
    "    \n",
    "    info = soup.find(class_ = \"book-wrapper__top-section--details\")\n",
    "    \n",
    "    # Get the author's name(s) and websites\n",
    "    author_metadata = info.findAll(class_ = 'sp__author-link')\n",
    "    book_author = []\n",
    "    author_links = []\n",
    "    \n",
    "    for data in author_metadata:\n",
    "        # Author(s)\n",
    "        author = data.string\n",
    "        book_author.append(author)\n",
    "        # Author(s) webpages\n",
    "        author_link = data.get('href')\n",
    "        author_links.append(author_link)\n",
    "        \n",
    "    # Save the data\n",
    "    authors.append(' & '.join(book_author))\n",
    "    authors_webpages.append(' & '.join(author_links))\n",
    "    \n",
    "    \n",
    "    # Publish date\n",
    "    publish = info.find(class_ = 'sp__published')\n",
    "    publish_date = re.sub('Published: ', '', publish.string)\n",
    "    publish_dates.append(publish_date)\n",
    "    \n",
    "    # Number of pages\n",
    "    num_pages = info.find(class_ = 'sp__the-pages').string\n",
    "    pages_string = re.sub(' pp.', '', num_pages)\n",
    "    book_length.append(int(pages_string))\n",
    "    \n",
    "    # Price\n",
    "    price = info.find(class_ = 'sp__price').string\n",
    "    prices.append(price)\n",
    "    \n",
    "    # Purchase links\n",
    "    purchase_link = info.find(class_ = 'retail-link').get('href')\n",
    "    purchase_links.append(purchase_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    \"title\": titles,\n",
    "    \"link\": links,\n",
    "    \"authors\": authors,\n",
    "    \"authors_webpage\": authors_webpages,\n",
    "    \"publish_date\": publish_dates,\n",
    "    \"book_length\": book_length,\n",
    "    \"price\": prices,\n",
    "    \"purchase_links\": purchase_links\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>authors</th>\n",
       "      <th>authors_webpage</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>book_length</th>\n",
       "      <th>price</th>\n",
       "      <th>purchase_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Future</td>\n",
       "      <td>https://mitpress.mit.edu/9780262534819/the-future</td>\n",
       "      <td>Nick Montfort</td>\n",
       "      <td>https://mitpress.mit.edu/author/nick-montfort-...</td>\n",
       "      <td>December 8, 2017</td>\n",
       "      <td>192</td>\n",
       "      <td>$15.95</td>\n",
       "      <td>https://www.penguinrandomhouse.com/search/site...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Critical Thinking</td>\n",
       "      <td>https://mitpress.mit.edu/9780262538282/critica...</td>\n",
       "      <td>Jonathan Haber</td>\n",
       "      <td>https://mitpress.mit.edu/author/jonathan-haber...</td>\n",
       "      <td>April 7, 2020</td>\n",
       "      <td>232</td>\n",
       "      <td>$15.95</td>\n",
       "      <td>https://www.penguinrandomhouse.com/search/site...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hunting</td>\n",
       "      <td>https://mitpress.mit.edu/9780262543293/hunting</td>\n",
       "      <td>Jan E. Dizard &amp; Mary Zeiss Stange</td>\n",
       "      <td>https://mitpress.mit.edu/author/jan-e-dizard-3...</td>\n",
       "      <td>October 4, 2022</td>\n",
       "      <td>248</td>\n",
       "      <td>$16.95</td>\n",
       "      <td>https://www.penguinrandomhouse.com/search/site...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Content</td>\n",
       "      <td>https://mitpress.mit.edu/9780262543286/content</td>\n",
       "      <td>Kate Eichhorn</td>\n",
       "      <td>https://mitpress.mit.edu/author/kate-eichhorn-...</td>\n",
       "      <td>May 10, 2022</td>\n",
       "      <td>192</td>\n",
       "      <td>$15.95</td>\n",
       "      <td>https://www.penguinrandomhouse.com/search/site...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Machine Learning, revised and updated edition</td>\n",
       "      <td>https://mitpress.mit.edu/9780262542524/machine...</td>\n",
       "      <td>Ethem Alpaydın</td>\n",
       "      <td>https://mitpress.mit.edu/author/ethem-alpaydn-...</td>\n",
       "      <td>August 17, 2021</td>\n",
       "      <td>280</td>\n",
       "      <td>$15.95</td>\n",
       "      <td>https://www.penguinrandomhouse.com/search/site...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0                                     The Future   \n",
       "1                              Critical Thinking   \n",
       "2                                        Hunting   \n",
       "3                                        Content   \n",
       "4  Machine Learning, revised and updated edition   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://mitpress.mit.edu/9780262534819/the-future   \n",
       "1  https://mitpress.mit.edu/9780262538282/critica...   \n",
       "2     https://mitpress.mit.edu/9780262543293/hunting   \n",
       "3     https://mitpress.mit.edu/9780262543286/content   \n",
       "4  https://mitpress.mit.edu/9780262542524/machine...   \n",
       "\n",
       "                             authors  \\\n",
       "0                      Nick Montfort   \n",
       "1                     Jonathan Haber   \n",
       "2  Jan E. Dizard & Mary Zeiss Stange   \n",
       "3                      Kate Eichhorn   \n",
       "4                     Ethem Alpaydın   \n",
       "\n",
       "                                     authors_webpage      publish_date  \\\n",
       "0  https://mitpress.mit.edu/author/nick-montfort-...  December 8, 2017   \n",
       "1  https://mitpress.mit.edu/author/jonathan-haber...     April 7, 2020   \n",
       "2  https://mitpress.mit.edu/author/jan-e-dizard-3...   October 4, 2022   \n",
       "3  https://mitpress.mit.edu/author/kate-eichhorn-...      May 10, 2022   \n",
       "4  https://mitpress.mit.edu/author/ethem-alpaydn-...   August 17, 2021   \n",
       "\n",
       "   book_length   price                                     purchase_links  \n",
       "0          192  $15.95  https://www.penguinrandomhouse.com/search/site...  \n",
       "1          232  $15.95  https://www.penguinrandomhouse.com/search/site...  \n",
       "2          248  $16.95  https://www.penguinrandomhouse.com/search/site...  \n",
       "3          192  $15.95  https://www.penguinrandomhouse.com/search/site...  \n",
       "4          280  $15.95  https://www.penguinrandomhouse.com/search/site...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=metadata)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data\n",
    "Save as a csv and excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder\n",
    "path = os.path.realpath('saved_data')\n",
    "\n",
    "# CSV file\n",
    "df.to_csv(path+'\\\\data.csv', index=False)\n",
    "\n",
    "# Excel file\n",
    "df.to_excel(path+'\\\\data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7ba2c2a3e8ffbea87cf1bc2bc8053571429eea774ae9f19e45b45234d58901a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
